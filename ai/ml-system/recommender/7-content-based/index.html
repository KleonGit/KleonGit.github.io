<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">

  <!-- PACE Progress Bar START -->
  
    <script src="/lib/pace/pace.min.js"></script>
    <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  
  

  <!-- PACE Progress Bar START -->

  
  <title>机器学习系统 4-7 - 基于内容的推荐算法 | KLEON</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="AI,IT">
  
  
  
  
  <meta name="description" content="基于内容的推荐算法又叫基于标签的推荐算法，是最早被大规模应用的，思路直观，仍在系统冷启动中发挥作用。">
<meta name="keywords" content="机器学习,推荐系统">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习系统 4-7 - 基于内容的推荐算法">
<meta property="og:url" content="https://blog.kleon.space/ai/ml-system/recommender/7-content-based/index.html">
<meta property="og:site_name" content="KLEON">
<meta property="og:description" content="基于内容的推荐算法又叫基于标签的推荐算法，是最早被大规模应用的，思路直观，仍在系统冷启动中发挥作用。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2021-05-02T12:24:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习系统 4-7 - 基于内容的推荐算法">
<meta name="twitter:description" content="基于内容的推荐算法又叫基于标签的推荐算法，是最早被大规模应用的，思路直观，仍在系统冷启动中发挥作用。">
  
    <link rel="alternate" href="/atom.xml" title="KLEON" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  <!-- 
    <link href="//fonts.loli.net/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
   -->
  <!-- <link href="https://fonts.loli.net/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.loli.net/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css"> -->
  <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <!-- <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style> -->
    
  <!-- <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.loli.net/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all"> -->
  <link rel="stylesheet" href="/css/style.css">

  <script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/3.0.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/hiero.css">
  <link rel="stylesheet" href="/css/glyphs.css">
  

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/my.css">
  <!-- Google Adsense -->
  
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
      (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-0123456789ABCDEF",
          enable_page_level_ads: true
      });
  </script>
  
</head>
</html>
<script>
var themeMenus = {};

  themeMenus["/"] = "首页"; 

  themeMenus["/archives"] = "归档"; 

</script>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  <header id="allheader" class="site-header" role="banner">
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" title="KLEON" rel="home"> KLEON </a>
            
          </h1>

          
            <div class="site-description">Think About The Big Map</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>
            <div class="clearfix sf-menu">

              <ul id="main-nav" class="nmenu sf-js-enabled">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">首页</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">归档</a> </li>
                    
              </ul>
            </div>
          </nav>


      </div>
  </div>
</header>


  <div id="originBgDiv" style="background: #fff; width: 100%;">

      <div style="max-height:600px; overflow: hidden;  display: flex; display: -webkit-flex; align-items: center;">
        <img id="originBg" width="100%" alt="" src="">
      </div>

  </div>

  <script>
  function setAboutIMG(){
      var imgUrls = "css/images/pose.jpg,https://source.unsplash.com/collection/954550/1920x1080".split(",");
      var random = Math.floor((Math.random() * imgUrls.length ));
      if (imgUrls[random].startsWith('http') || imgUrls[random].indexOf('://') >= 0) {
        document.getElementById("originBg").src=imgUrls[random];
      } else {
        document.getElementById("originBg").src='/' + imgUrls[random];
      }
  }
  bgDiv=document.getElementById("originBgDiv");
  if(location.pathname.match('about')){
    setAboutIMG();
    bgDiv.style.display='block';
  }else{
    bgDiv.style.display='none';
  }
  </script>



  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-ai/ml-system/recommender/7-content-based" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      机器学习系统 4-7 - 基于内容的推荐算法
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	发布于 <time datetime="2021-05-02T12:25:10.000Z" itemprop="datePublished">五月 2, 2021</time>
	&nbsp;&nbsp;
	更新于 <time datetime="2021-05-02T12:24:56.000Z" itemprop="datePublished">五月 2, 2021</time>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>基于内容的推荐算法又叫基于标签的推荐算法，是最早被大规模应用的，思路直观，仍在系统冷启动中发挥作用。</p>
<a id="more"></a>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>所谓基于内容的推荐算法(Content-Based Recommendations)是基于标的物相关信息、用户相关信息及用户对标的物的操作行为来构建推荐算法模型，为用户提供推荐服务。这里的标的物相关信息可以是对标的物文字描述的metadata信息、标签、用户评论、人工标注的信息等。用户相关信息是指人口统计学信息(如年龄、性别、偏好、地域、收入等等)。用户对标的物的操作行为可以是评论、收藏、点赞、观看、浏览、点击、加购物车、购买等。基于内容的推荐算法一般只依赖于用户自身的行为为用户提供推荐，不涉及到其他用户的行为。</p>
<p>基于内容的个性化推荐，一般需要三个步骤：</p>
<ol>
<li>基于用户信息及用户操作行为构建用户特征表示</li>
<li>基于标的物信息构建标的物特征表示</li>
<li>基于用户及标的物特征表示为用户推荐标的物</li>
</ol>
<h2 id="基于用户和标的物特征为用户推荐的核心思想"><a href="#基于用户和标的物特征为用户推荐的核心思想" class="headerlink" title="基于用户和标的物特征为用户推荐的核心思想"></a>基于用户和标的物特征为用户推荐的核心思想</h2><ul>
<li>基于用户历史行为记录做推荐</li>
</ul>
<p>我们需要事先计算标的物之间的相似性，然后将用户历史记录中的标的物的相似标的物推荐给用户。</p>
<p>不管标的物包含哪类信息，一般的思路是将标的物特征转化为向量化表示，有了向量化表示，我们就可以通过cosine余弦相似度计算两个标的物之间的相似度了。</p>
<ul>
<li>用户和标的物特征都用显式的标签表示，利用该表示做推荐</li>
</ul>
<p>标的物用标签来表示，那么反过来，每个标签就可以关联一组标的物，那么根据用户的标签表示，用户的兴趣标签就可以关联到一组标的物，这组通过标签关联到的标的物，就可以作为给用户的推荐候选集。这类方法就是所谓的倒排索引法，是搜索业务通用的解决方案。</p>
<ul>
<li>用户和标的物嵌入到同一个向量空间，基于向量相似做推荐</li>
</ul>
<p>当用户和标的物嵌入到同一个向量空间中后，我们就可以计算用户和标的物之间的相似度，然后按照标的物跟用户的相似度，为用户推荐相似度高的标的物。还可以基于用户向量表示计算用户相似度，将相似用户喜欢的标的物推荐给该用户，这时标的物嵌入是不必要的。</p>
<h2 id="基于用户信息及用户操作行为构建用户特征表示"><a href="#基于用户信息及用户操作行为构建用户特征表示" class="headerlink" title="基于用户信息及用户操作行为构建用户特征表示"></a>基于用户信息及用户操作行为构建用户特征表示</h2><p>用户的特征表示可以基于用户对标的物的操作行为(如点击、购买、收藏、播放等)构建用户对标的物的偏好画像，也可以基于用户自身的人口统计学特征来表达。有了用户特征表示，我们就可以基于用户特征为用户推荐与他特征匹配的标的物。构建用户特征的方法主要有如下5种：</p>
<ul>
<li>用户行为记录作为显示特征</li>
</ul>
<p>记录用户过去一段时间对标的物的偏好。拿视频行业来说，如果用户过去一段时间看了A、B、C三个视频，同时可以根据每个视频用户观看时长占视频总时长的比例给用户的行为打分(<script type="math/tex">S_1</script>,<script type="math/tex">S_2</script>,<script type="math/tex">S_3</script>)，这时用户的兴趣偏好就可以记录为：</p>
<script type="math/tex; mode=display">
{(A,S_1),(B,S_2),(C,S_3)}</script><p>该方案直接将用户历史操作过的标的物作为用户的特征表示，在推荐时可以将与用户操作过的标的物相似的标的物推荐给用户。</p>
<ul>
<li>显式的标签特征</li>
</ul>
<p>如果标的物是有标签来描述的，那么这些标签可以用来表征标的物。用户的兴趣画像也可以基于用户对标的物的行为来打上对应的标签。拿视频推荐来举例，如果用户过去看了科幻和恐怖两类电影，那么恐怖、科幻就是用户的偏好标签了。</p>
<p>每个标的物的标签可以是包含权重的，而用户对标的物的操作行为也是有权重的，从而用户的兴趣标签是有权重的。</p>
<p>在具体推荐时，可以将用户的兴趣标签关联到的标的物(具备该标签的标的物)推荐给用户。</p>
<ul>
<li>向量式的兴趣特征</li>
</ul>
<p>可以基于标的物的信息将标的物嵌入到向量空间中，利用向量来表示标的物，我们会在后面讲解嵌入的算法实现方案。有了标的物的向量化表示，用户的兴趣向量就可以用他操作过的标的物的向量的平均向量来表示了。</p>
<p>这里表示用户兴趣向量有很多种策略，可以基于用户对操作过的标的物的评分以及时间加权来获取用户的加权偏好向量，而不是直接取平均。另外，我们也可以根据用户操作过的标的物之间的相似度，为用户构建多个兴趣向量(比如对标的物聚类，用户在某一类上操作过的标的物的向量均值作为用户在这个类别上的兴趣向量)，从而更好地表达用户多方位的兴趣偏好。</p>
<p>有了用户的兴趣向量及标的物的兴趣向量，可以基于向量相似性计算用户对标的物的偏好度，再基于偏好度大小来为用户推荐标的物。</p>
<ul>
<li>通过交互方式获取用户兴趣标签</li>
</ul>
<p>很多APP在用户第一次注册时让用户选择自己的兴趣标签，一旦用户勾选了自己的兴趣标签，那么这些兴趣标签就是系统为用户提供推荐的原材料。具体推荐策略与上面一样。</p>
<ul>
<li>用户的人口统计学特征</li>
</ul>
<p>用户在登陆、注册时提供的关于自身相关的信息、通过运营活动用户填写的信息、通过用户行为利用算法推断得出的结论，如年龄、性别、地域、收入、爱好、居住地、工作地点等是非常重要的信息。基于这些关于用户维度的信息，我们可以将用户特征用向量化表示出来，向量的维度就是可获取的用户特征数。</p>
<p>有了用户特征向量就可以计算用户相似度，将相似用户喜欢的标的物推荐给该用户。</p>
<h2 id="基于标的物信息构建标的物特征表示"><a href="#基于标的物信息构建标的物特征表示" class="headerlink" title="基于标的物信息构建标的物特征表示"></a>基于标的物信息构建标的物特征表示</h2><p>标的物的特征，一般可以利用显式的标签来表示，也可以利用隐式的向量(当然one-hot编码也是向量表示，但是不是隐式的)来刻画，向量的每个维度就是一个隐式的特征项。前面提到某些推荐算法需要计算标的物之间的相似度，下面我们在讲标的物的各种特征表示时，也简单介绍一下标的物之间的相似度计算方法。顺便说一下，标的物关联标的物的推荐范式也需要知道标的物之间的相似度。下面我们从4个方面来详细讲解怎么构建标的物的特征表示。</p>
<ul>
<li>标的物包含标签信息</li>
</ul>
<p>最简单的方式是将将标签按照某种序排列，每个标签看成一个维度，那么每个标的物就可以表示成一个N维的向量了(N是标签的个数)，如果标的物包含某个标签，向量在相应标签的分量上的值为1，否则为0，即所谓的one-hot编码。有可能N非常大(如视频行业，N可能是几万、甚至几十万上百万)，这时向量是稀疏向量(一般标的物只有少量的几个或者几十个标签)，我们可以采用稀疏向量的表示来优化向量存储和计算，提升效率。有了标的物基于标签的向量化表示，很容易基于cosine余弦计算相似度了。</p>
<p>实际上标签不是这么简单的，有很多业务标签是分级的，比如电商(如淘宝)，有多级的标签(见下面图3)，标签的层级关系形成一颗树状结构，这时该怎么向量化呢？最简单的方案是只考虑叶子节点的标签(也是最低层级的标签)，基于叶子节点标签构建向量表示。更复杂的方法，可以基于层级结构构建标签表示及计算标的物相似度。</p>
<p>标签可以是通过算法获取的，比如通过NLP技术从文本信息中提取关键词作为标签。对于图片/视频，它们的描述信息(标题等)可以提取标签，另外可以通过目标检测的方法从图片/视频中提取相关对象构建标签。</p>
<p>标签可以是用户打的，很多产品在用户与标的物交互时可以为标的物打标签，这些标签就是标的物的一种刻画。标签也可是人工标注的，像Netflix在做推荐时，请了上万个专家对视频从上千个维度来打标签，让标签具备非常高的质量。基于这么精细优质的标签做推荐，效果一定不错。很多行业的标的物来源于第三方提供商，他们在入驻平台时会被要求按照某些规范填写相关标签信息(比如典型的如电商)。</p>
<ul>
<li>标的物具备结构化的信息</li>
</ul>
<p>有些行业标的物是具备结构化信息的，如视频行业，一般会有媒资库，媒资库中针对每个节目会有标题、演职员、导演、标签、评分、地域等维度数据，这类数据一般存在关系型数据库中。这类数据，我们可以将一个字段(也是一个特征)作为向量的一个维度，这时向量化表示每个维度的值不一定是数值，但是形式还是向量化的形式，即所谓的向量空间模型（Vector Space Model，简称VSM）。这时我们可以通过如下的方式计算两个标的物之间的相似度。</p>
<script type="math/tex; mode=display">
V_1 = (p_1, p_2, p_3, ..., p_k)</script><script type="math/tex; mode=display">
V_2 = (q_1, q_2, q_3, ..., q_k)</script><script type="math/tex; mode=display">
sim(V_1, V_2) = \sum_{t=1}^{k}w_t*sim(p_t, q_t)</script><ul>
<li>包含文本信息的标的物的特征表示</li>
</ul>
<p>像今日头条和手机百度APP这类新闻资讯或者搜索类APP，标的物就是一篇篇的文章(其中会包含图片或者视频)，文本信息是最重要的信息形式，构建标的物之间的相似性有很多种方法。下面对常用的方法做一些讲解说明。</p>
<p>z. 词袋模型</p>
<p>统计所有文档中词出现的频次转化为向量。</p>
<p>词袋随新词不断增大，矩阵非常稀疏，未保留句法。</p>
<p>a. 利用TF-IDF将文本信息转化为特征向量</p>
<p>TF-IDF通过将所有文档(即标的物)分词，获得所有不同词的集合(假设有M个词)，那么就可以为每个文档构建一个M维(每个词就是一个维度)的向量，而该向量中某个词所在维度的值可以通过统计每个词在文档中的重要性来衡量，这个重要性的度量就是TF-IDF。<br>TF即某个词在某篇文档中出现的频次，用于衡量这个词在文档中的重要性，出现次数越多的词重要性越大，当然我们会提前将“的”、“地”、“啊”等停用词去掉，这些词对构建向量是没有任何实际价值的，甚至是有害的。<script type="math/tex">t_k</script>是第k个词，<script type="math/tex">d_j</script>是第j个文档。</p>
<script type="math/tex; mode=display">
TF(t_k, d_j) = \frac{|| t_k \in d_j  ||}{|| d_j ||}</script><p>IDF代表的是某个词在所有文档中的“区分度”，如果某个词只在少量几个文档中出现，那么它包含的价值就是巨大的(所谓物以稀为贵)，如果某个词在很多文档中出现，那么它就不能很好地衡量(区分出)这个文档。N是所有文档的个数，<script type="math/tex">n_k</script>是包含<script type="math/tex">t_k</script>的文档个数。</p>
<script type="math/tex; mode=display">
IDF(t_k) = log\frac{N}{n_k}</script><script type="math/tex; mode=display">
TF-IDF(t_k, d_j) = TF(t_k, d_j) * IDF(t_k)</script><p>有了基于TF-IDF计算的标的物的向量表示，我们就很容易计算两个标的物之间的相似度了(cosine余弦相似度)。</p>
<p>b. 利用LDA算法构建文章(标的物)的主题</p>
<p>LDA算法是一类文档主题生成模型，包含词、主题、文档三层结构，是一个三层的贝叶斯概率模型。 对于语料库中的每篇文档，LDA定义了如下生成过程（generative process）：</p>
<p>[1] 对每一篇文档，从主题分布中抽取一个主题；<br>[2] 从上述被抽到的主题所对应的单词分布中抽取一个单词；<br>[3] 重复上述过程直至遍历文档中的每一个单词。</p>
<p>我们通过对所有文档进行LDA训练，就可以构建每篇文档的主题分布，从而构建一个基于主题的向量(每个主题就是向量的一个分量，而值就是该主题的概率值)，这样我们就可以利用该向量来计算两篇文档的相似度了。主题模型可以理解为一个降维过程，将文档的词向量表示降维成主题的向量表示(主题的个数是远远小于词的个数的，所以是降维)。</p>
<p>c. 利用doc2vec算法构建文本相似度</p>
<p>doc2vec或者叫做 paragraph2vec, sentence embeddings，是一种非监督式算法，可以获得 句子、段落、文章的稠密向量表达，它是 word2vec 的拓展，2014年被Google的两位大牛提出，并大量用于文本分类和情感分析中。通过doc2vec学出句子、段落、文章的向量表示，可以通过计算向量之间距离来表达句子、段落、文章之间的相似性。</p>
<p>这里我们简单描述一下doc2vec的核心思想。doc2vec受word2vec启发，由它推广而来，我们先来简单解释一下word2vec的思路。</p>
<p>word2vec<a href="#refer-21"><sup>21</sup></a> <a href="#refer-22"><sup>22</sup></a>通过学习一个唯一的向量表示每个词，每个词向量作为矩阵W中的一列(W是所有词的词向量构成的矩阵)，矩阵列可以通过词汇表为每个词做索引，排在索引第一位的放到矩阵W的第一列，如此类推。将学习问题转化为通过上下文词序列中前几个词来预测下一个词。<br>word2vec可以用CBOW, Skipgram训练模型。Skipgram主要通过输入句子中特定的单词来预测该单词周边的其他单词。CBOW是通过目标单词周边的单词来预测目标单词，这点刚好跟skip-gram模型相反。Python包Gensim<a href="#refer-23"><sup>23</sup></a>可用来训练Word2Vec/Doc2Vec。</p>
<p>doc2vec类似地，每个段落/文档表示为向量，作为矩阵D的一列，每个词也表示为一个向量，作为矩阵W中的一列。将学习问题转化为通过上下文词序列中前几个词和段落/文档来预测下一个词。将段落/文档和词向量通过拼接或者平均来预测句子的下一个词(下图是通过“the”、“cat”、“sat”及段落id来预测下一个词“on”)。在训练的时候我们固定上下文的长度，用滑动窗口的方法产生训练集。段落向量/句向量在上下文中共享。</p>
<ul>
<li>图片、音频、视频</li>
</ul>
<p>如果标的物包含的是图片、音频或者视频信息，处理起来会更加复杂。一种方法是利用它们的文本信息(标题、评论、描述信息、利用图像技术提取的字幕等文本信息等等，对于音频，可以通过语音识别转化为文本)采用上面(3)的技术方案获得向量化表示。对于图像或者视频，也可以利用openCV中的PSNR和SSIM算法来表示视频特征，也可以计算视频之间的相似度。另外一种可行的方法是采用图像、音频处理技术直接从图像、视频、音频中提取特征进行向量化表示，从而容易计算出相似度。总之，图片、图像、音频都可以转化为NLP问题或者图像处理问题(见下面图6)，通过图像处理和NLP获得对应的特征表示，从而最终计算出相似度，这里不详细讲解。</p>
<h2 id="基于用户及标的物特征表示为用户推荐标的物"><a href="#基于用户及标的物特征表示为用户推荐标的物" class="headerlink" title="基于用户及标的物特征表示为用户推荐标的物"></a>基于用户及标的物特征表示为用户推荐标的物</h2><ul>
<li>采用跟基于物品的协同过滤类似的方式推荐</li>
</ul>
<p>该方法采用基于用户行为记录的显式特征表示用户特征，通过将用户操作过的标的物最相似的标的物推荐给用户，算法原理跟基于物品的协同过滤类似，计算公式甚至是一样的，但是这里计算标的物相似度是基于标的物的自身信息来计算的，而基于物品的协同过滤是基于用户对标的物的行为矩阵来计算的。</p>
<p>用户<script type="math/tex">u</script>对标的物<script type="math/tex">s</script>的喜好度<script type="math/tex">sim(u,s)</script>，可以表示为：</p>
<script type="math/tex; mode=display">
sim(u, s) = \sum_{s_i\inS} score(u, s_i) * sim(s_i, s)</script><p>其中<script type="math/tex">S</script>是所有用户操作过的标的物的列表，<script type="math/tex">score(u, s_i)</script>是用户<script type="math/tex">u</script>对标的物<script type="math/tex">s_i</script>的喜好度，<script type="math/tex">sim(s_i, s)</script>是标的物<script type="math/tex">s_i</script>和<script type="math/tex">s</script>的相似度。有了用户对每个标的物的相似度，基于相似度降序排列，就可以取topN推荐给用户了。</p>
<p>除了采用上面的公式外，我们在推荐时也可以稍作变化，采用最近邻方法(K-Nearest Neighbor, KNN)。对于用户操作/喜欢过的每个标的物，通过kNN找到最相似的k个标的物。</p>
<ul>
<li>采用跟基于用户协同过滤类似的方法计算推荐</li>
</ul>
<p>如果我们获得了用户的人口统计学向量表示或者基于用户历史操作行为获得了用户的向量化表示，那么我们可以采用跟基于用户的协同过滤方法相似的方法来为用户提供个性化推荐，具体思路如下：</p>
<p>我们可以将与该用户最相似的用户喜欢的标的物推荐给该用户，算法原理跟基于用户的协同过滤类似，计算公式甚至是一样的。但是这里计算用户相似度是基于用户的人口统计学特征向量表示来计算的(计算用户向量cosine余弦相似度)或者是基于用户历史行为嵌入获得的特征向量来计算的，而基于用户的协同过滤是基于用户对标的物的行为矩阵来计算用户之间的相似度。</p>
<p>用户<script type="math/tex">u</script>对标的物<script type="math/tex">s</script>的喜好度<script type="math/tex">sim(u,s)</script>，可以表示为：</p>
<script type="math/tex; mode=display">
sim(u, s) = \sum_{s_i\inU} sim(u, u_i) * score(u_i, s)</script><p>其中<script type="math/tex">U</script>是与该用户最相似的用户集合，<script type="math/tex">score(u_i, s)</script>是用户<script type="math/tex">u</script>对标的物<script type="math/tex">s</script>的喜好度，<script type="math/tex">sim(u_i, u)</script>是标的物<script type="math/tex">u_i</script>和<script type="math/tex">u</script>的相似度。有了用户对每个标的物的相似度，基于相似度降序排列，就可以取topN推荐给用户了。</p>
<p>与前面一样我们也可以采用最近邻方法(K-Nearest Neighbor, KNN)。通过kNN找到最相似的k个用户，将这些用户操作/喜欢过的每个标的物推荐给用户。</p>
<ul>
<li>基于标的物聚类的推荐</li>
</ul>
<p>有了标的物的向量表示，我们可以用kmeans等聚类算法将标的物聚类，有了标的物的聚类，推荐就好办了。从用户历史行为中的标的物所在的类别挑选用户没有操作行为的标的物推荐给用户，这种推荐方式是非常直观自然的。</p>
<ul>
<li>基于向量相似的推荐</li>
</ul>
<p>不管是前面提到的用户的显示的兴趣特征(利用标签来衡量用户兴趣)或者是向量式的兴趣特征(将用户的兴趣投影到向量空间)，我们都可以获得用户兴趣的向量表示。</p>
<p>如果我们获得了用户的向量表示和标的物的向量表示，那么我们就可以通过向量的cosine余弦相似度计算用户与标的物之间的相似度。一样地，有了用户对每个标的物的相似度，基于相似度降序排列，就可以取topN推荐给用户了。</p>
<p>基于向量的相似的推荐，需要计算用户向量与每个标的物向量的相似性。如果标的物数量较多，整个计算过程还是相当耗时的。同样地，计算标的物最相似的K个标的物，也会涉及到与每个其他的标的物计算相似度，也是非常耗时的。</p>
<p>整个计算过程的时间复杂度是<script type="math/tex">O(N^2)</script>，N是标的物的总数。</p>
<p>上述复杂的计算过程可以利用Spark等分布式计算平台来加速计算。对于T+1级(每天更新一次推荐结果)的推荐服务，利用Spark事先计算好，将推荐结果存储起来供前端业务调用是可以的。</p>
<p>另外一种可行的策略是利用高效的向量检索库，在极短时间(一般几毫秒或者几十毫秒)内为用户索引出topN最相似的标的物。目前FaceBook开源的FAISS库(<a href="https://github.com/facebookresearch/faiss)就是一个高效的向量搜索与聚类库，可以在毫秒级响应查询及聚类需求，因此可以用于个性化的实时推荐。目前国内有很多公司将该库用到了推荐业务上。" target="_blank" rel="noopener">https://github.com/facebookresearch/faiss)就是一个高效的向量搜索与聚类库，可以在毫秒级响应查询及聚类需求，因此可以用于个性化的实时推荐。目前国内有很多公司将该库用到了推荐业务上。</a></p>
<p>FAISS库适合稠密向量的检索和聚类，所以对于利用LDA、Doc2vector算法构建向量表示的方案是实用的，因为这些方法构建的是稠密向量。而对于TF-IDF及基于标签构建的向量化表示，就不适用了，这两类方法构建的都是稀疏的高维向量。</p>
<ul>
<li>基于标签的反向倒排索引做推荐</li>
</ul>
<p>基于标的物的标签和用户的历史兴趣，我们可以构建出用户基于标签兴趣的画像及标签与标的物的倒排索引查询表(熟悉搜索的同学应该不难理解)。基于该反向索引表及用户的兴趣画像，我们就可以为用户做个性化推荐了。该类算法其实就是基于标签的召回算法。</p>
<p>具体推荐过程是这样的：从用户画像中获取用户的兴趣标签，基于用户的兴趣标签从倒排索引表中获取该标签对应的标的物，这样就可以从用户关联到标的物了。其中用户的每个兴趣标签及标签关联到的标的物都是有权重的。</p>
<h1 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h1><p>基于内容的推荐是最古老的一类推荐算法，在整个推荐系统发展史上具有举足轻重的地位。虽然它的效果可能没有协同过滤及新一代推荐算法好，但是它们还是非常有应用价值的，甚至是必不可少的。基于内容的推荐算法主要用在如下几类场景。</p>
<ul>
<li>完全个性化推荐</li>
</ul>
<p>就是基于内容特征来为每个用户生成不同的推荐结果，我们常说的推荐系统就是指这类推荐形态。上面一节已经完整地讲解了怎么为用户做个性化推荐，这里不再赘述。</p>
<ul>
<li>的物关联标的物推荐</li>
</ul>
<p>标的物关联标的物的推荐也是工业界最常用的推荐形态，大量用于真实产品中。</p>
<p>上一节讲了很多怎么构建标的物之间相似度的方法，其实这些方法可以直接用来做标的物关联标的物的推荐，只要我们将与某个标的物最相似的topN的标的物作为关联推荐即可。</p>
<ul>
<li>配合其他推荐算法</li>
</ul>
<p>由于基于内容的推荐算法在精准度上不如协同过滤等算法，但是可以更好的适应冷启动，所以在实际业务中基于内容的推荐算法会配合其他算法一起服务于用户，最常用的方法是采用级联的方式，先给用户协同过滤的推荐结果，如果该用户行为少没有协同过滤推荐结果，就为该用户推荐基于内容的推荐算法产生的推荐结果。</p>
<ul>
<li>主题推荐</li>
</ul>
<p>如果我们有标的物的标签信息，并且基于标签系统构建了一套推荐算法，那么我们就可以将用户喜欢的标签采用主题的方式推荐给用户，每个主题就是用户的一个兴趣标签。通过一些列主题的罗列展示，让用户从中筛选自己感兴趣的内容(见下面图8)。Netflix的首页大量采用基于主题的推荐模式。主题推荐的好处是可以将用户所有的兴趣点按照兴趣偏好大小先后展示出来，可解释性强，并且让用户有更多维度的自由选择空间。</p>
<ul>
<li>给用户推荐标签</li>
</ul>
<p>另外一种可行的推荐策略是不直接给用户推荐标的物，而是给用户推荐标签，用户通过关注推荐的标签，自动获取具备该标签的标的物。除了可以通过推荐的标签关联到标的物获得直接推荐标的物类似的效果外，间接地通过用户对推荐的标签的选择、关注进一步获得了用户的兴趣偏好，这是一种可行的推荐产品实现方案。</p>
<h1 id="优劣"><a href="#优劣" class="headerlink" title="优劣"></a>优劣</h1><p>基于内容的推荐算法算是一类比较直观易懂的算法，目前在工业级推荐系统中有大量的使用场景，在本节我们对基于内容的推荐算法的优缺点加以说明，方便读者在实践中选择取舍，构建适合业务场景的内容推荐系统。</p>
<p>优点：</p>
<p>基于上面的介绍，基于内容的推荐算法是非常直观的，具体来说，它有如下6个优点。</p>
<p>（1）可以很好的识别用户的口味<br>该算法完全基于用户的历史兴趣来为用户推荐，推荐的标的物也是跟用户历史兴趣相似的，所以推荐的内容一定是符合用户的口味的。</p>
<p>（2）非常直观易懂，可解释性强<br>基于内容的推荐算法基于用户的兴趣为用户推荐跟他兴趣相似的标的物，原理简单，容易理解。同时，由于是基于用户历史兴趣推荐跟兴趣相似的标的物，用户也非常容易接受和认可。</p>
<p>（3）可以更加容易的解决冷启动<br>只要用户有一个操作行为，就可以基于内容为用户做推荐，不依赖其他用户行为。同时对于新入库的标的物，只要它具备metadata信息等标的物相关信息，就可以利用基于内容的推荐算法将它分发出去。因此，对于强依赖于UGC内容的产品(如抖音、快手等)，基于内容的推荐可以更好地对标的物提供方进行流量扶持。</p>
<p>（4）算法实现相对简单<br>基于内容的推荐可以基于标签维度做推荐，也可以将标的物嵌入向量空间中，利用相似度做推荐，不管哪种方式，算法实现较简单，有现成的开源的算法库供开发者使用，非常容易落地到真实的业务场景中。</p>
<p>（5）对于小众领域也能有比较好的推荐效果<br>对于冷门小众的标的物，用户行为少，协同过滤等方法很难将这类内容分发出去，而基于内容的算法受到这种情况的影响相对较小。</p>
<p>（6）非常适合标的物快速增长的有时效性要求的产品<br>对于标的物增长很快的产品，如今日头条等新闻资讯类APP，基本每天都有几十万甚至更多的标的物入库，另外标的物时效性也很强。新标的物一般用户行为少，协同过滤等算法很难将这些大量实时产生的新标的物推荐出去，这时就可以采用基于内容的推荐算法更好地分发这些内容。</p>
<p>缺点：</p>
<p>虽然基于内容的推荐实现相对容易，解释性强，但是基于内容的推荐算法存在一些不足，导致它的效果及应用范围受到一定限制。主要的问题有如下4个：</p>
<p>（1）推荐范围狭窄，新颖性不强<br>由于该类算法只依赖于单个用户的行为为用户做推荐，推荐的结果会聚集在用户过去感兴趣的标的物类别上，如果用户不主动关注其他类型的标的物，很难为用户推荐多样性的结果，也无法挖掘用户深层次的潜在兴趣。特别是对于新用户，只有少量的行为，为用户推荐的标的物较单一。</p>
<p>（2）需要知道相关的内容信息且处理起来较难<br>内容信息主要是文本、视频、音频，处理起来费力，相对难度较大，依赖领域知识。同时这些信息更容易有更大概率含有噪音，增加了处理难度。另外，对内容理解的全面性、完整性及准确性会影响推荐的效果。</p>
<p>（3）较难将长尾标的物分发出去<br>基于内容的推荐需要用户对标的物有操作行为，长尾标的物一般操作行为非常少，只有很少用户操作，甚至没有用户操作。由于基于内容的推荐只利用单个用户行为做推荐，所以更难将它分发给更多的用户。</p>
<p>（4）推荐精准度不太高<br>基于工业界的实践经验，相比协同过滤算法，基于内容的推荐算法精准度要差一些。</p>
<h1 id="落地"><a href="#落地" class="headerlink" title="落地"></a>落地</h1><p>基于内容的推荐算法虽然容易理解，实现起来相对简单，但在落地到真实业务场景中，有很多问题需要思考解决。下面这些问题是在落地基于内容推荐算法时必须思考的，这里将他们列举出来，并提供一些简单的建议，希望可以帮到读者。</p>
<ul>
<li>内容来源的获取</li>
</ul>
<p>对于基于内容的推荐来说，有完整的、高质量的内容信息是可以构建精准的推荐算法的基础，那我们有哪些方法可以获取内容来源呢？下面这些策略是主要获取内容(包括标的物内容和用户相关内容)来源的手段。</p>
<p>（1）标的物“自身携带”的信息<br>标的物在上架时，第三方会准备相关的内容信息，如天猫上的商品在上架时会补充很多必要的信息。对于视频来说，各类metadata信息也是视频入库时需要填充的信息。我们要做的是增加对新标的物入库的监控和审核，及时发现信息不全的情况并做适当处理。</p>
<p>（2）通过爬虫获取标的物相关信息<br>通过爬虫爬取的信息可以作为标的物信息的补充，特别是补充上面（1）不全的信息。有了更完整的信息就可以获得更好的特征表示。</p>
<p>（3）通过人工标注数据<br>往往人工标注的数据价值密度高，通过人工精准的标注可以大大提升算法推荐的精准度。但是人工标注成本太大。</p>
<p>（4）通过运营活动或者产品交互让用户填的内容<br>通过抽奖活动让用户填写家庭组成、兴趣偏好等，在用户开始注册时让用户填写兴趣偏好特征，这些都是获取内容的手段。</p>
<p>（5）通过收集用户行为直接获得或者预测推断出的内容<br>通过请求用户GPS位置知道用户的活动轨迹，用户购物时填写收货地址，用户绑定的身份证和银行卡等，通过用户操作行为预测出用户的兴趣偏好，这些方法都可以获得部分用户数据。</p>
<p>（6）通过与第三方合作或者产品矩阵之间补充信息<br>目前中国有大数据交易市场，通过正规的数据交易或者跟其他公司合作，在不侵犯用户隐私的情况下，通过交换数据可以有效填补自己产品上缺失的数据。</p>
<p>如果公司有多个产品，新产品可以借助老产品的巨大用户基数，将新产品的用户与老产品用户关联起来(id-maping或者账号打通)，这样老产品上丰富的用户行为信息可以赋能给新产品。</p>
<ul>
<li>怎么利用负反馈</li>
</ul>
<p>用户对标的物的操作行为不一定代表正向反馈，有可能是负向的。比如点开一个视频，看了不到几秒就退出来了，明显表明用户不喜欢。有很多产品会在用户交互中直接提供负向反馈能力，这样可以收集到更多负向反馈。</p>
<p>负向反馈代表用户强烈的不满，因此如果推荐算法可以很好的利用这些负向反馈就能够大大提升推荐系统的精准度和满意度。基于内容的推荐算法整合负向反馈的方式有如下几种：</p>
<p>(1) 将负向反馈整合到算法模型中<br>在构建算法模型中整合负向反馈，跟正向反馈一起学习，从而更自然地整合负向反馈信息。</p>
<p>(2) 采用事后过滤的方式<br>先给用户生成推荐列表，再从该推荐列表中过滤掉与负向反馈关联的或者相似的标的物。</p>
<p>(3) 采用事前处理的方式<br>从待推荐的候选集中先将与负向反馈相关联或者相似的标的物剔除掉，然后再进行相关算法的推荐。</p>
<ul>
<li>兴趣随时间变化</li>
</ul>
<p>用户的兴趣不是一成不变的，一般用户的兴趣是随着时间变化的，那怎么在算法中整合用户的兴趣变化呢？可行的策略是对用户的兴趣根据时间衰减，最近的行为给予最大的权重。还可以分别给用户建立短期兴趣特征和长期兴趣特征，在推荐时既考虑短期兴趣又考虑长期兴趣，最终推荐列表中整合两部分的推荐结果。</p>
<p>对于新闻资讯等这类时效性强的产品，能够整合用户的实时兴趣变化可以大大提升用户体验，这也是现在信息流类推荐产品大行其道的原因。</p>
<ul>
<li>数据清洗</li>
</ul>
<p>基于内容的推荐算法依赖于标的物相关的描述信息，这些信息更多的是以文本的形式存在，这就涉及到自然语言处理了，文本中可能会存在很多歧义、符号、脏数据，我们需要事先对数据进行很好的处理，才能让后续的推荐算法产生好的效果。</p>
<ul>
<li>加速计算与节省资源</li>
</ul>
<p>在实际推荐算法落地时，我们会事先为每个标的物计算N(=50)个最相似的标的物，事先将计算好的标的物存起来，减少时间和空间成本，方便后续更好地做推荐。同时也可以利用各种分布式计算平台和快速查询平台(如Spark、FAISS库等)加速计算过程。另外，算法开发过程中尽量做到模块化，对业务做抽象封装，这可以大大提升开发效率，并且可能会节省很多资源。</p>
<ul>
<li>怎么解决基于内容的推荐越推越窄的问题</li>
</ul>
<p>前面提到基于内容的推荐存在越推越窄的缺点，那怎么避免或者减弱这种影响呢？当然用协同过滤等其他算法是一个有效的方法。另外，我们可以给用户做兴趣探索，为用户推荐兴趣之外的特征关联的标的物，通过用户的反馈来拓展用户兴趣空间，这类方法就是强化学习中的EE方法。如果我们构造了标的物的知识图谱系统，我们就可以通过图谱拓展标的物更远的联系，通过长线的相关性来做推荐，同样可以有效解决越推越窄的问题。</p>
<ul>
<li><p>工程落地技术选型<br>本篇文章主要讲的是基于内容的推荐系统的算法实现原理，具体工程实践时，需要考虑到数据处理、模型训练、分布式计算等技术，当前很多开源方案可以使用，常用的如Spark mllib，scikit-learn，Tensorflow，pytorch，gensim等，这些工具都封装了很多数据处理、特征提取、机器学习算法，我们可以基于第二节的算法思路来落地实现。</p>
</li>
<li><p>业务的安全性<br>除了技术外，在推荐产品落地中还需要考虑推荐的标的物的安全性，避免推荐反动、色情、标题党、低俗内容，这些就需要基于NLP或者CV技术对文本或者视频进行分析过滤。如果是UGC平台型的产品，还需要考虑怎么激励优质内容创作者，让好的内容得到更多的分发机会，同时对产生劣质内容的创作者采取一定的惩罚措施，比如限制发文频率、禁止一段时间的发文权限等。</p>
</li>
</ul>
<hr>

      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/推荐系统/">推荐系统</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

      
            
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/ai/ml-system/recommender/6-ab-test/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          机器学习系统 4-6 - AB测试
        
      </div>
    </a>
  
  
    <a href="/ai/ml-system/recommender/8-collaborative-filter/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">机器学习系统 4-8 - 协同过滤</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article" style="overflow-y: scroll; max-width: 28%;">
    <strong class="toc-title">文章目录</strong>
    
      <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#原理"><span class="nav-number">1.</span> <span class="nav-text">原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基于用户和标的物特征为用户推荐的核心思想"><span class="nav-number">1.1.</span> <span class="nav-text">基于用户和标的物特征为用户推荐的核心思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于用户信息及用户操作行为构建用户特征表示"><span class="nav-number">1.2.</span> <span class="nav-text">基于用户信息及用户操作行为构建用户特征表示</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于标的物信息构建标的物特征表示"><span class="nav-number">1.3.</span> <span class="nav-text">基于标的物信息构建标的物特征表示</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于用户及标的物特征表示为用户推荐标的物"><span class="nav-number">1.4.</span> <span class="nav-text">基于用户及标的物特征表示为用户推荐标的物</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#场景"><span class="nav-number">2.</span> <span class="nav-text">场景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#优劣"><span class="nav-number">3.</span> <span class="nav-text">优劣</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#落地"><span class="nav-number">4.</span> <span class="nav-text">落地</span></a></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2018-2021 KLEON All Rights Reserved.
      </div>
      <div class="site-count">
          
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var contentdiv = document.getElementById("content");

    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
</script>

<!-- Custome JS -->
<script src="/js/my.js"></script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



  <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.css">
  <script src="https://cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.js"></script>


<script src="/js/scripts.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>







  <div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>








  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
